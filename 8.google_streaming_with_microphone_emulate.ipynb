{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Google-Cloud-Speech-to-Text-API-Microphone-Streaming-emulate\" data-toc-modified-id=\"Google-Cloud-Speech-to-Text-API-Microphone-Streaming-emulate-1\">Google Cloud Speech-to-Text API Microphone Streaming emulate</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Microphone-Streaming-emulate\" data-toc-modified-id=\"Microphone-Streaming-emulate-1.0.1\">Microphone Streaming emulate</a></span></li><li><span><a href=\"#위의-기능을-Python-module로-작성한-기능-테스트\" data-toc-modified-id=\"위의-기능을-Python-module로-작성한-기능-테스트-1.0.2\">위의 기능을 Python module로 작성한 기능 테스트</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Speech-to-Text API Microphone Streaming emulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Microphone 오디오 파일을 Streaming 방식으로 처리하는 샘플(실제는 저장된 오디오 파일을 읽어서 Streaming 방식으로 처리)\n",
    "- https://cloud.google.com/speech-to-text/docs/streaming-recognize?hl=ko#speech-streaming-mic-recognize-python\n",
    "- **Microphone Streaming 오디오 처리는 300초 시간 제한이 있음** : 더 긴 파일은 파일을 잘라서 처리하는 방법을 사용할 수 있음<br>\n",
    "   (OutOfRange: 400 Exceeded maximum allowed stream duration of 305 seconds.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Microphone Streaming emulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import wave\n",
    "\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "\n",
    "import pyaudio\n",
    "from six.moves import queue\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MicrophoneStream(object):\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "    def __init__(self, rate, chunk):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1, rate=self._rate,\n",
    "            input=True, frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "#         self._buff.put(in_data)\n",
    "        data = wf.readframes(frame_count)\n",
    "        self._buff.put(data)\n",
    "        stream.write(data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b''.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def listen_print_loop(responses):\n",
    "    \"\"\"Iterates through server responses and prints them.\n",
    "\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "\n",
    "    Each response may contain multiple results, and each result may contain\n",
    "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
    "    print only the transcription for the top alternative of the top result.\n",
    "\n",
    "    In this case, responses are provided for interim results as well. If the\n",
    "    response is an interim one, print a line feed at the end of it, to allow\n",
    "    the next result to overwrite it, until the response is a final one. For the\n",
    "    final one, print a newline to preserve the finalized transcription.\n",
    "    \"\"\"\n",
    "    num_chars_printed = 0\n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        # The `results` list is consecutive. For streaming, we only care about\n",
    "        # the first result being considered, since once it's `is_final`, it\n",
    "        # moves on to considering the next utterance.\n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        # Display the transcription of the top alternative.\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "        #\n",
    "        # If the previous result was longer than this one, we need to print\n",
    "        # some extra spaces to overwrite the previous result\n",
    "        overwrite_chars = ' ' * (num_chars_printed - len(transcript))\n",
    "\n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + '\\r')\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            num_chars_printed = len(transcript)\n",
    "\n",
    "        else:\n",
    "            print(transcript + overwrite_chars)\n",
    "\n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            if re.search(r'\\b(exit|quit)\\b', transcript, re.I):\n",
    "                print('Exiting..')\n",
    "                break\n",
    "\n",
    "            num_chars_printed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def microphone_streaming_start():\n",
    "    # See http://g.co/cloud/speech/docs/languages\n",
    "    # for a list of supported languages.\n",
    "    language_code = 'ko-KR'\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code,\n",
    "        enable_automatic_punctuation=True,\n",
    "        enable_word_time_offsets=True)\n",
    "    #     enable_speaker_diarization=True,\n",
    "    #     diarization_speaker_count=3)\n",
    "\n",
    "    streaming_config = types.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True)\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (types.StreamingRecognizeRequest(audio_content=content)\n",
    "                    for content in audio_generator)\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        # Now, put the transcription responses to use.\n",
    "        listen_print_loop(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FILE_NAME = \"19m_20181220_deominju_16000.wav\"\n",
    "wf = wave.open(\"audio_file/\"+ FILE_NAME, 'rb')     # 300초 이상의 파일은 분할해서 처리 해야 함\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                channels=wf.getnchannels(),\n",
    "                rate=wf.getframerate(),\n",
    "                output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 반갑습니다. 제 115차 정책조정회의 일을 홍영표 원내대표에 모드 바람으로 11 12 월 이렇게 보내기가. 아, 이제 일주일 앞으로 다가왔습니다. 여야가 민생법안 처리를 해서 노니의 속도를 더 내야겠습니다. 꼭 처리해야 할 일이 토파즈는 6300번 산업안전보건법입니다. 6003번 오늘 일찍 의견에 법안소위에서 노니 될 예정입니다. 오늘 합의가 이루어지지 않을 경우 27분의 철인가 사실상 어렵습니다. 자유한국당 너 우리 아이들을 위한은 마음이 조금이라도 있다면 일 1003번 노니 접수 임해야 합니다.\r"
     ]
    }
   ],
   "source": [
    "# 중단된 경우 재실행 하면 중단된 부분부터 시작됨\n",
    "try:\n",
    "    microphone_streaming_start()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위의 기능을 Python module로 작성한 기능 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import google_stt as stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"witch_hunt_2_online-audio-converter.com_16000.wav\"\n",
    "wf = wave.open(\"audio_file/\"+ FILE_NAME, 'rb')     # 300초 이상의 파일은 분할해서 처리 해야 함\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                channels=wf.getnchannels(),\n",
    "                rate=wf.getframerate(),\n",
    "                output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "근데 연예인 중에서도 함께 많이 방송을 뭘 하게 될 일이 생기면 전전긍긍하고 제작장 댁에서 좀 빼 달라 나는 같이 지금 할 수가 끝까지 그런 거 조심하는 경우가 있고 어떤 분들은 또 천연덕스럽게 조는 괜찮고 훌륭하게 대처하는 분들도 계시더라구요. 어때요? 방송에 나와요. 뭐 예전에 잠깐 이렇게 사겼던 그런 사람인데 갑자기 반천계곡 예. 예 많이 힘들죠. 그냥 조그만 맞는구나 해서 헤어진 가벼운 관계는 그래. 우리 이모 친구는 계속 지내자. 근데 정말 막 축구 못살고 막 그러다가 어쩔 수 없는 이유로 헤어졌으면 나중에 만나서 친구 잘 지내는가? 이렇게 되는 거 이상한 거 아닌가요? 잘 지내는가?  \n",
      "좋아했던 사람 자료 왔는가 보통 치료가 잘 안 되는 거예요. 그냥 쉽게 쉽게 만나는 스타일이 수도 있을 것 같아요. 근데 문제는이 여자가 딴 거를 못 해. 그렇지. 이런데 사 준다는 거야이 말을 할 때 얼마나 많은게 맞는 얘기고 못하는 얘기하며 방송용으로 창동역 역삼동 헤어졌어요. 상대방에게 다시 연락 없어요. 미친 거 같아. 다음에 술 마시고 전화 한 거야. 그래서 막 약속할 수 없는 말들을 자꾸 문자로 보내는 거예요. 다음날 되면 또 필요하거든. 당연히 병원에 있어요. 좀 받아 본 적이 있죠 있어요. 지금 어디야? 왜 보고 싶어서\n",
      "여보세요. 마이크가 어디야? 뉘앙스가 그냥 지금 만나서 오늘 같이 있자. 뭐 이런 느낌이었어요. 아니, 그렇게 만나서 회포를 푸순 있겠죠? 하룻밤 근데 없고 하루 지나고 난 술도 깨고 나면 사랑하지 못하는 그런게 있지 않냐? 술취해서 전화한 거 그다음에 일어나는데 발신 열 두 번인데 0초 0초 0초 0초 0초 12분 이런 거 있잖아요. 참 술 먹었을 때 아침 일어나지마 주종 했던 거 핸드폰 확인했어요. 했나 누구한테 전화했는지 누구한테 문자 보냈는지 그리고 무슨 사진 찍은지\n",
      "아니면 큰 나라는 기억안날때 무슨 사진 있는지 아니? 근데 이렇게 보고 소스라치게 놀란 적이 있지요. 이런 사진 왜 그런 거였지? 어? 거기가 있었지? 그렇군요. 지금 그러면은 사람들한테 많은 사람을 봤잖아요. 뒤에서 걱정해 주는 사람이 많아요. 알파 지랄하지 말라고 그런 거 같아요. 쌤이 술을 먹으면 조금 거칠어지는 느낌이 있다는 예전에 주소 좀 있었더라고요. 얘기하기 좀 그렇겠죠. 들어본 적이 그럼요. 당연하죠. 그냥 호주.       \n",
      "행정 지역인데 쓰레기라고 그러더라고 너무 보고 싶어. 빨리 정리를 하자면 저는 오후에 사무실 이야기하는 쿨하게 헤어지는 것 불가능하다고 아름다운 이별 미드가 사람들을 많이 망쳐 놨어. 그래요. 뭐 연락을 한다고 칩시다. 근데 그거를 굳이 내 앞에서 할 필요 없다고 생각해. 만약에 내가 아끼는 사람이 그로 인해 스트레스를 받는다고 얘기했으면 9시 그 앞에서 어. 그래. 그거는 별론 거 같아. 그래. 친구 관계 내 앞에서 통화 하지 마라. 내가 마음이 너무 아파. 여자도 좀 더 조심하려고 하고 그런 그렇게 돼야 되는게 좋은 거 아니에요. 그래서 오늘 뭐 이거 목소리가 들려 함께 해 봤습니다. 남자분들 여자분들 이야기 좋고요.\n",
      "사랑은 용기있는자가 쟁취한다. 너 옛날 말입니다. 사람 그린라이트를 이거는 제가 칭찬합니다. 알송 달송 어려운 신호들을 저희가 놓치지않고\r"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    stt.microphone_streaming_start(wf, stream)    # 함수 호출을 위해 객체 전달\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
